{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base algorithm for features' importance classification for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "labels = [\"NoEvents\", \"Attack\", \"Natural\"]\n",
    "\n",
    "X = pd.read_csv(\"Data/data%d.csv\"%1) #read file\n",
    "\n",
    "X = X.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#preparing the label converter\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "y = le.transform(X['marker'])\n",
    "X = X.drop(columns='marker')\n",
    "\n",
    "features = list(X.columns)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_features = 'log2')\n",
    "X=X.values\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "explainer = LimeTabularExplainer(X, training_labels = y, feature_names = features, class_names = labels)\n",
    "\n",
    "\n",
    "Xall = []\n",
    "for i in range(2,16):\n",
    "    Xall.append(pd.read_csv(\"Data/data%d.csv\"%i))\n",
    "\n",
    "Xall = pd.concat(Xall)\n",
    "Xall = Xall.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "yall = le.transform(Xall['marker'])\n",
    "Xall = Xall.drop(columns='marker')\n",
    "\n",
    "boole = (yall != clf.predict(Xall))\n",
    "\n",
    "res = []\n",
    "\n",
    "for act_class in [0, 1, 2]:\n",
    "    faulty = boole & (yall == act_class)\n",
    "    X_test = Xall[faulty]\n",
    "    y_test = yall[faulty]\n",
    "    lst = []\n",
    "    for idx in range(0, 100):\n",
    "        exp = explainer.explain_instance(X_test.iloc[idx], clf.predict_proba, num_features=128, labels=[0, 1, 2])\n",
    "        lst.append(exp.as_list(label=0))\n",
    "    lst = np.array(lst)\n",
    "    clst = np.concatenate(lst, axis=0)\n",
    "    dtfr = pd.DataFrame(clst, columns=['feature', 'importance'])\n",
    "    dtfr[\"importance\"] = pd.to_numeric(dtfr[\"importance\"])\n",
    "    dtfr = dtfr.groupby(['feature']).mean()\n",
    "    res.append(dtfr.sort_values(by=\"importance\"))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[                       importance\n feature                          \n R4-PM8:V > 0.00         -0.012310\n R3:F > 60.00            -0.011923\n R1-PA3:VH > 78.00       -0.011004\n R3-PA7:VH <= -101.22    -0.010964\n R3-PA10:IH > 102.93     -0.010511\n ...                           ...\n R4-PA4:IH <= -97.95      0.005985\n R2-PM4:I <= 320.95       0.006062\n R1-PA:Z > 12.43          0.006171\n R3-PM2:V <= 128425.29    0.007994\n R4-PA2:VH > 117.68       0.010149\n \n [368 rows x 1 columns],                               importance\n feature                                 \n R3:F > 60.00                   -0.010821\n R1-PA3:VH > 78.00              -0.010649\n R3-PA1:VH <= -101.21           -0.009657\n R3-PA7:VH <= -101.22           -0.009517\n R3-PA10:IH > 102.93            -0.009034\n ...                                  ...\n R2-PA2:VH > 114.00              0.009784\n R2-PA6:IH <= -114.38            0.010825\n -97.40 < R1-PA1:VH <= -35.86    0.010908\n R4-PA2:VH > 117.68              0.010962\n -97.43 < R1-PA7:VH <= -35.85    0.014091\n \n [380 rows x 1 columns],                               importance\n feature                                 \n R3:F > 60.00                   -0.010580\n R1-PA3:VH > 78.00              -0.010439\n R3-PA10:IH > 102.93            -0.010019\n R1-PA1:VH > 71.28              -0.009285\n R1-PA7:VH > 71.26              -0.008303\n ...                                  ...\n -62.63 < R3-PA10:IH <= 34.66    0.005893\n R3-PA7:VH > 65.92               0.005920\n R2-PM4:I <= 320.95              0.006481\n R1-PA:Z > 12.43                 0.006621\n R3-PM2:V <= 128425.29           0.007478\n \n [331 rows x 1 columns]]"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosen features values modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.72      0.87      0.78     51797\n      Attack       0.29      0.16      0.21     17382\n     Natural       0.25      0.05      0.08      4232\n\n    accuracy                           0.65     73411\n   macro avg       0.42      0.36      0.36     73411\nweighted avg       0.59      0.65      0.61     73411\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yall, clf.predict(Xall), labels=[0,1,2], target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmod = Xall.copy()\n",
    "\n",
    "def modify(feat, val):\n",
    "    Xmod[feat] =Xmod[feat].apply(lambda x: x + val)\n",
    "\n",
    "\n",
    "modify(\"R4-PA2:VH\", -117.68)\n",
    "modify(\"R3-PM2:V\", 128525.29)\n",
    "modify(\"R1-PA:Z\", -12.43)\n",
    "modify(\"R2-PM4:I\", 320.95)\n",
    "modify(\"R4-PA4:IH\", -97.95)\n",
    "\n",
    "modify(\"R1-PA7:VH\", 61.58)\n",
    "modify(\"R4-PA2:VH\", 117.68)\n",
    "modify(\"R1-PA1:VH\", 61.54)\n",
    "modify(\"R2-PA6:IH\", 114.38)\n",
    "modify(\"R2-PA2:VH\", -114)\n",
    "\n",
    "modify(\"R3-PM2:V\", 128425.29)\n",
    "modify(\"R1-PA:Z\", -12.43)\n",
    "modify(\"R2-PM4:I\", 320.95)\n",
    "modify(\"R3-PA7:VH\", -65.92)\n",
    "modify(\"R3-PA10:IH\", 97.29)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.71      0.89      0.79     51797\n      Attack       0.28      0.13      0.18     17382\n     Natural       0.26      0.05      0.08      4232\n\n    accuracy                           0.66     73411\n   macro avg       0.42      0.36      0.35     73411\nweighted avg       0.58      0.66      0.61     73411\n\n"
    }
   ],
   "source": [
    "print(classification_report(yall, clf.predict(Xmod), labels=[0,1,2], target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    def __init__(self):\n",
    "        self.noevents = None\n",
    "        self.attack = None\n",
    "        self.natural = None\n",
    "\n",
    "    def distance(self, X1, X2):\n",
    "        return np.abs(((X1 - X2).sum()))\n",
    "\n",
    "    def important(self, X):\n",
    "        return X[[\"R4-PA4:IH\" , \"R2-PM4:I\", \"R1-PA:Z\", \"R3-PM2:V\", \"R4-PA2:VH\", \"R2-PA2:VH\", \"R2-PA6:IH\", \"R1-PA1:VH\", \"R4-PA2:VH\", \"R1-PA7:VH\", \"R3-PA10:IH\", \"R3-PA7:VH\", \"R2-PM4:I\", \"R1-PA:Z\", \"R3-PM2:V\"]]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xnew = self.important(X)\n",
    "        self.noevents = Xnew[y == 0].mean(axis=0)\n",
    "        self.attack = Xnew[y == 1].mean(axis=0)\n",
    "        self.natural = Xnew[y == 2].mean(axis=0)     \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xnew = self.important(X)\n",
    "        res = np.c_[np.apply_along_axis(lambda x: self.distance(x, self.noevents), axis=1, arr=Xnew), np.apply_along_axis(lambda x: self.distance(x, self.attack), axis=1, arr=Xnew), np.apply_along_axis(lambda x: self.distance(x, self.natural), axis=1, arr=Xnew)]\n",
    "        return np.c_[Xnew, np.argmin(res, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('dist', <__main__.Distance object at 0x00000262202DFF88>),\n                ('RandomForest', RandomForestClassifier(max_features='log2'))])"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "labels = [\"NoEvents\", \"Attack\", \"Natural\"]\n",
    "\n",
    "X = pd.read_csv(\"Data/data%d.csv\"%1) #read file\n",
    "\n",
    "X = X.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#preparing the label converter\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "y = le.transform(X['marker'])\n",
    "X = X.drop(columns='marker')\n",
    "\n",
    "pipe = Pipeline([('dist', Distance()) , ('RandomForest', RandomForestClassifier(n_estimators=100, max_features = 'log2'))])\n",
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.71      0.83      0.77     51797\n      Attack       0.27      0.19      0.22     17382\n     Natural       0.18      0.05      0.07      4232\n\n    accuracy                           0.63     73411\n   macro avg       0.39      0.36      0.36     73411\nweighted avg       0.58      0.63      0.60     73411\n\n"
    }
   ],
   "source": [
    "Xall = []\n",
    "for i in range(2,16):\n",
    "    Xall.append(pd.read_csv(\"Data/data%d.csv\"%i))\n",
    "\n",
    "Xall = pd.concat(Xall)\n",
    "Xall = Xall.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "yall = le.transform(Xall['marker'])\n",
    "Xall = Xall.drop(columns='marker')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(yall, pipe.predict(Xall), labels=[0,1,2], target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GaussianHMM(n_components=3)"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "clf2 = GaussianHMM(3)\n",
    "clf2.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = clf2.get_stationary_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctest = RandomForestClassifier(n_estimators = 100, max_features = 'log2', class_weight = {0: coefs[0], 1:coefs[1], 2:coefs[2]})\n",
    "ctest1 = RandomForestClassifier(n_estimators = 100, max_features = 'log2' ,class_weight = {0: coefs[0], 1:coefs[1], 2:coefs[2]}, criterion=\"entropy\")\n",
    "ctest2= RandomForestClassifier(n_estimators = 100, max_features = 'log2', class_weight = \"balanced\")\n",
    "ctest3= RandomForestClassifier(n_estimators = 100, max_features = 'log2', class_weight = \"balanced\", criterion= \"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.72      0.87      0.78     51797\n      Attack       0.29      0.16      0.21     17382\n     Natural       0.25      0.05      0.08      4232\n\n    accuracy                           0.65     73411\n   macro avg       0.42      0.36      0.36     73411\nweighted avg       0.59      0.65      0.61     73411\n\n              precision    recall  f1-score   support\n\n    NoEvents       0.71      0.86      0.78     51797\n      Attack       0.29      0.17      0.21     17382\n     Natural       0.28      0.05      0.09      4232\n\n    accuracy                           0.65     73411\n   macro avg       0.43      0.36      0.36     73411\nweighted avg       0.59      0.65      0.61     73411\n\n              precision    recall  f1-score   support\n\n    NoEvents       0.72      0.85      0.78     51797\n      Attack       0.30      0.19      0.24     17382\n     Natural       0.25      0.05      0.09      4232\n\n    accuracy                           0.65     73411\n   macro avg       0.42      0.37      0.37     73411\nweighted avg       0.59      0.65      0.61     73411\n\n              precision    recall  f1-score   support\n\n    NoEvents       0.71      0.85      0.78     51797\n      Attack       0.29      0.18      0.22     17382\n     Natural       0.27      0.05      0.09      4232\n\n    accuracy                           0.65     73411\n   macro avg       0.42      0.36      0.36     73411\nweighted avg       0.59      0.65      0.61     73411\n\n              precision    recall  f1-score   support\n\n    NoEvents       0.71      0.85      0.78     51797\n      Attack       0.27      0.16      0.20     17382\n     Natural       0.26      0.05      0.09      4232\n\n    accuracy                           0.64     73411\n   macro avg       0.41      0.36      0.36     73411\nweighted avg       0.58      0.64      0.60     73411\n\n              precision    recall  f1-score   support\n\n    NoEvents       0.71      0.86      0.78     51797\n      Attack       0.28      0.16      0.20     17382\n     Natural       0.29      0.06      0.10      4232\n\n    accuracy                           0.65     73411\n   macro avg       0.43      0.36      0.36     73411\nweighted avg       0.58      0.65      0.60     73411\n\n"
    }
   ],
   "source": [
    "ctest.fit(X,y)\n",
    "ctest1.fit(X,y)\n",
    "ctest2.fit(X,y)\n",
    "ctest3.fit(X,y)\n",
    "\n",
    "clf3= RandomForestClassifier(n_estimators = 100, max_features = 'log2', criterion=\"entropy\")\n",
    "clf3.fit(X,y)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(yall, clf.predict(Xall), labels=[0,1,2], target_names=labels))\n",
    "print(classification_report(yall, clf3.predict(Xall), labels=[0,1,2], target_names=labels))\n",
    "print(classification_report(yall, ctest.predict(Xall), labels=[0,1,2], target_names=labels))\n",
    "print(classification_report(yall, ctest1.predict(Xall), labels=[0,1,2], target_names=labels))\n",
    "print(classification_report(yall, ctest2.predict(Xall), labels=[0,1,2], target_names=labels))\n",
    "print(classification_report(yall, ctest3.predict(Xall), labels=[0,1,2], target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598717797817",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}