\chapter{Introduction} \label{chap:intro}

Cyber-Physical Systems (CPS) are nowadays widely used in different application domains, such as smart-homes, smart-cities, hospitals, etc... They are mainly composed of two entities: a cyber part consisting in a computing and networking component, and a physical part consisting in different controllers and sensors. The existence of a connected cyber part implies its susceptibility to multiple cyber threats. The malfunctioning of these systems, due to a cyber threat, can cause severe impacts on the real life and the safety of the community, for example a blackout or water contamination. That is why many algorithms have been designed for the security monitoring of those systems, in particular the anomaly and attack detection.

Nowadays, machine and deep learning algorithms are used to detect those anomalies and intrusions. But, in majority, they rely only on the cyber part of the systems and on the data describing their behaviour, ignoring their physical models. The \textbf{goal} of this master thesis is to \textbf{employ a hybrid machine learning algorithm, in particular neural networks, to detect anomalies and attacks in CPS considering its physical model}.

However this is not the first time such a fusion is examined. In the literature various approaches of the fusion of neural networks with theory-based models were presented. Due to research, five different methods were found. First, an approach that add physic based features like \cite{karpatne_physics-guided_2018}. Then, another approach generating huge datasets artificially and learn the machine learning model to find the suspicious values of sensors rather than deciding in which status is the system, like in \cite{ferragut_real-time_2017}. Third, a method that reduces the dimensionality of the problem, like in \cite{swischuk_projection-based_2019}. Fourth, a method that works on data defined over graphs, like in \cite{zamzam_physics-aware_2019}, and finally an approach that decomposes the problem into smaller ones, like in \cite{karpatne_theory-guided_2017}.

The first mentioned approach takes into consideration a physical model of the system. Based on the sensors' data, the physical model will generate additional physical features. Finally, those physical features, along with sensor's data are passed to the machine learning algorithm. This algorithm was visualized in figure \ref{fig:vis_feat1}.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[rectangle, draw=black](data) {Dataset};
        \node[rectangle, draw=black](phmodel) [below=of data] {Physical model};
        \node[rectangle, draw=black](phfeat) [below=of phmodel] {Physical features};
        \node[rectangle, draw=black](model) [right=of phmodel] {Machine learning algorithm};
        \node[rectangle, draw=black](out) [right=of model] {Predicted class};

        \draw[->] (data.south) -- (phmodel.north);
        \draw[->] (phmodel.south) -- (phfeat.north); 
        \draw[->] (data.east) -- (model.west);
        \draw[->] (phfeat.east) -- (model.west);
        \draw[->] (model.east) -- (out.west);
    \end{tikzpicture}
    \caption{Physical features addition algorithm visualization} \label{fig:vis_feat1}
\end{figure}

In \cite{karpatne_physics-guided_2018} this approach was used to model water temperature in a lake at varying times and depths. As physical model, they used the state-of-the-art general lake model \cite{hipsey_glm_2014} to obtain the temperatures obtained via simulation. Moreover, their approach incorporates a loss-function composed of three main components: the empirical error, the structural error and the physical inconsistency. The loss-function is a function that the machine learning algorithm tends to minimize during the training process. The empirical error evaluates the difference between the predicted and expected values, the structural error is proportional to the model complexity, whereas the physical inconsistency evaluates if the predicted value is physically correct. The authors of \cite{karpatne_physics-guided_2018} have proven that their approach gives better results that other attempts to resolve the same problem.

The second approach, on other hand, presented in \cite{ferragut_real-time_2017}, takes into consideration an attack generation engine. This engine takes as an input a configuration file describing the system then it creates thousands of samples with various features describing sensors readings and others physic based. Then, the attacks are simulated by spoofing the values of samples. The dataset obtained this way is then trained to a machine learning algorithm, which will be able to tell to which extent the values of the features are physically correct. A simplified illustration of the training process of the algorithm is presented in figure \ref{fig:vis_feat2}.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}[every text node part/.style={align=center}]
        \node[rectangle, draw=black](conf) {Configuration \\file};
        \node[rectangle, draw=black](gen) [right=of conf] {Attack \\generation \\engine};
        \node[rectangle, draw=black](model) [right=of gen] {Machine \\learning\\ algorithm};
        \node[rectangle, draw=black](out1) [right=of model] {Feature 1 probability};
        \node[rectangle, draw=black](out2) [below=of out1] {Feature 2 probability};
        \node[rectangle](out3) [below=of out2] {...};
        \node[rectangle, draw=black](out4) [below=of out3] {Feature n probability};

        \draw[->] (conf.east) -- (gen.west);
        \draw[->, very thick] (gen.east) -- (model.west);
        \draw[->] (model.east) -- (out1.west);
        \draw[->] (model.east) -- (out2.west);
        \draw[->] (model.east) -- (out4.west);
    \end{tikzpicture}
    \caption{Attack generation approach training algorithm visualization} \label{fig:vis_feat2}
\end{figure}

The authors of \cite{ferragut_real-time_2017} presented their work on the example of a power system, in particular the IEEE 30-bus test case model. They achieved an accuracy of 99\% with a neural network with a 60-node layer, which is a very good result. 

The third approach, proposed by \cite{swischuk_projection-based_2019}, uses so called proper orthogonal decomposition (POD) in order to reduce the dimensionality of the parameters of the system.  This parametrization is then combined with machine learning algorithms to learn the relationship between the input and the data obtained from the POD. The details of the POD algorithm will not be discussed due to their complexity.

The authors of this last paper, used various machine learning techniques like neural networks or decision tree and they presented multiple applications of their approach, however all of them where in the area of fluids. The obtained results in each case showed a significant improvement of accuracy.

The fourth approach, proposed by \cite{zamzam_physics-aware_2019} was described in particular on distribution system state estimation problem. Its role is to estimate the state of the system based on physical measurements. The accuracy of those measurements may vary, that is why they can be divided into smaller problems. This division into partitions is assured by using graphs to represent spatially the data.  The state estimation at a certain bus of the network can be limited to using the measurements from bus' partition(s). That is why the main idea behind the used neural network is to set the weights of the measurements outside this partition(s) to zero. The authors found that their approach is more performant than Gauss-Newton approach, which rely only on physics.

The final approach, presented in \cite{karpatne_theory-guided_2017}, suggests to create modular neural networks to solve complex problems by dividing them into smaller ones. This way multiple neural networks are created and trained using only data concerning the small problem that they solve. The authors of \cite{karpatne_theory-guided_2017} proposed in the same work many other approaches but they were already discussed.

All the discussed methods have one in common: they can only detect the malfunctioning in general, without differentiating between attacks and a normal fault. In this master thesis, an attempt will be made to develop an algorithm able to detect the system status - normal behaviour, a fault and an attack. In order to do that, the \textbf{scope of this thesis} includes a description of an example of cyber physical system, the description of different machine learning algorithms along with the comparison of their performances, the analysis of the importance of features and finally the proposal of three different solutions to the initial problem.

This thesis is composed of six chapters. The first chapter is the present introduction. The second chapter describes in details an example of a cyber-physical system provided with a ready to use datasets. The third chapter is a description of used machine learning toolkits, machine learning techniques and metrics for their evaluation. This chapter also includes a comparison of the values of those metrics in relation to the used techniques and toolkits. The fourth chapter is a description of different tools for the interpretation of results and the proposal of a simple algorithm to extract the most important features for the false predictions made by a classifier. The fifth chapter presents a proposal of three different techniques to answer the goal of this master thesis. This chapter comes with an analysis of the results obtained after applying those techniques. The last chapter presents the conclusions of this master thesis.