\chapter{Model enhancement}
After having chosen the appropriate machine learning algorithms and found a way to determine the most important features in the classification problem, this chapter is an attempt to create a model able to enhance the results obtained by the basic classification. Three different approaches are presented. First of all, the most important features values were altered and the effect of this modification is examined. Second, a formula for calculating the distance between different samples is established then a way to use that information. Finally, the Hidden Markov Models were used in order to determine the likeliness of prediction of a particular class and this data was used to modify the machine learning algorithm. 

\section{Features values modification}
The first proposed solution considers changing the values of most important features in the dataset after the training process. In other words the training process occurs normally, then the importances are determined and a correction function is created (figure \ref{fig:train}). This correction function will act then on the samples introduced to the model in order to change the features values and obtain better predictions (figure \ref{fig:predict}). 

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[rectangle, draw=black] (main) {Training data};
        \node[rectangle, draw=black] (DecisionTree) [right=of main] {Classifier};
        \node[rectangle, draw=black] (out1) [right=of DecisionTree] {Trained model};
        \node[rectangle, draw=black] (out2) [below=of out1] {Features importances};
        \node[rectangle, draw=black] (feat) [right=of out2] {Features correction model};
   
        \draw[->] (main.east) -- (DecisionTree.west);
        \draw[->] (DecisionTree.east) -- (out1.west);
        \draw[->] (DecisionTree.east) -- (out2.west); 
        \draw[->] (out2.east) -- (feat.west);
    \end{tikzpicture}
    \caption{Training process illustration} \label{fig:train}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[rectangle, draw=black] (main) {Sample};
        \node[rectangle, draw=black] (correl) [right=of main] {Features correction model};
        \node[rectangle, draw=black] (model) [right=of correl] {Trained model};
        \node[rectangle, draw=black](out) [right=of model] {Predicted class};

        \draw[->] (main.east) -- (correl.west);
        \draw[->] (correl.east) -- (model.west);
        \draw[->] (model.east) -- (out.west);
    \end{tikzpicture}
    \caption{Prediction illustration} \label{fig:predict}
\end{figure}

First of all the correction function was defined as the modification function of the feature values for the predicted samples. This modification consists in shifting the feature value so the feature value would not meet the condition to make a false prediction from tables \ref{tab:5best:noev}-\ref{tab:5best:natural}. This function python code is as follows:  
\begin{python}
def modify(feat, val):
    X[feat] = X[feat].apply(lambda x: x + val)
\end{python}
where \textit{X} is a pandas DataFrame object containing all the samples to predict.

Second, the five most important features are taken from tables \ref{tab:5best:noev}-\ref{tab:5best:natural} and the values of features from the samples to predict are altered using the previous function. The following code shows this operation:
\begin{python}
modify("R4-PA5:IH", -115.38)
modify("R3-PM2:V", 128525.29)
modify("R2-PM1:V", 2000)
modify("R1-PA12:IH", 32.04)
modify("R3-PM5:I", 330.7)
modify("R3:S", 0)
modify("R2-PA7:VH", 101.20)
modify("R2-PM1:V", -1300872.03)
modify("R3-PA7:VH", 101.22)
modify("R3-PA2:VH", 93.75)    
modify("R2:F", -60)
modify("R3:F", -60)
modify("R2-PA5:IH",- 63.30)
modify("R2-PM7:V", -130857.40) 
\end{python}

The samples modified this way are then used for the predictions. In order to check the success of this method, the classification\_report method from scikit-learn was used. The results before and after modifying the samples are displayed in tables \ref{tab:clreport:before} and \ref{tab:clreport:after}.

\begin{table}[H]
    \centering
    \caption{Classification report before features modification} \label{tab:clreport:before}
    \begin{tabular}{rcccc}\toprule
        & precision    &recall & f1-score  & support \\\midrule
            NoEvents  &   $  0.72 $  &  $ 0.76 $  &  $ 0.74 $  & $ 51797 $\\
              Attack   &  $  0.27 $   & $ 0.26 $  &  $ 0.26 $  & $ 17382 $\\
             Natural   &  $  0.19 $   & $ 0.08 $  &  $ 0.12 $  & $  4232 $\\
            accuracy   &            &          &  $0.60$  &   $73411$ \\
           macro avg   &  $  0.39 $   & $ 0.37 $  &  $ 0.37 $  & $ 73411 $\\
        weighted avg   &  $  0.58 $  &  $ 0.60 $  &  $ 0.59 $ &  $ 73411 $\\\bottomrule
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Classification report after features modification} \label{tab:clreport:after}   
    \begin{tabular}{rcccc}\toprule
        &precision   & recall & f1-score &  support  \\\midrule

        NoEvents   &    0.71   &   0.83  &    0.77   &  51797 \\
          Attack    &   0.26   &   0.17  &    0.21   &  17382 \\
         Natural   &    0.10   &   0.03   &   0.05  &    4232 \\
    
        accuracy    &          &          &   0.63   &  73411 \\
       macro avg    &   0.36   &   0.34   &   0.34   &  73411 \\
    weighted avg     &  0.57   &   0.63   &   0.59   &  73411    \\     \bottomrule   
    \end{tabular}
\end{table}

The tables \ref{tab:clreport:before} and \ref{tab:clreport:after} show a general increase of the accuracy of the model after changing the features. The more detailed results, show a remarkably better recall and f-measure for NoEvents class, with a small decrease of precision, but for all other classes a decrease can be observed for all the metrics. 

For this particular set of samples, there is a slight increase of weighted recall, weighted f-measure and accuracy. That it is why, it may be concluded that this method succeeded with this particular dataset, especially given the unequal distribution of the samples between classes and model's tendency to predict NoEvents class. However, with any other dataset, where the NoEvents class samples are less common compared to other classes, this method causes worse predictions.

\section{Distance between features}
The second proposed solution considers using a transformation routine, which, reduces the number of features to the 15 most important from tables \ref{tab:5best:noev}-\ref{tab:5best:natural} and adds another feature that represents the closest class to the treated sample. The prediction steps were illustrated on figure \ref{fig:distill}.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \node[rectangle, draw=black](sample) {Sample};
        \node[rectangle, draw=black](trans) [right=of sample] {Transformation};
        \node[rectangle, draw=black](class) [right=of trans] {Classifier};
        \node[rectangle, draw=black](out) [right=of class] {Predicted class};

        \draw[->] (sample.east) -- (trans.west);
        \draw[->] (trans.east) -- (class.west);
        \draw[->] (class.east) -- (out.west);
    \end{tikzpicture}
    \caption{Distance algorithm illustration}
    \label{fig:distill}
\end{figure}

The transformation routine on other hand takes the form of a python class and is composed of 4 methods:
\begin{enumerate}
    \item \textbf{distance(X1, X2)}: returns the distance between two samples X1 and X2. It is calculated as the sum of differences between features,
    \item \textbf{important(X)}: returns the samples with only 15 most important features. The input must be a pandas DataFrame or Series. The choice of features to keep is made by hand directly in the method, without the possibility to change them afterwards,
    \item \textbf{fit(X,y)}: determines the reference class sample for each class by calculating the mean value of each feature among all samples corresponding to the treated class. It is called only during data fitting to the classifier,
    \item \textbf{transform(X)}: determines the class with the smallest distance to the sample, based on reference samples determined by fit(X,y) method. The obtained values are then added as a new feature to the samples X and returned afterwards by the method.
\end{enumerate}

This routine has been coupled with DecisionTree classifier using \textbf{pipeline} class in scikit-learn, which construct acts like a classifier (has fit and predict methods). 

The success rate of this method was verified, once more, using classification\_report method from scikit-learn. The result before the test are the same as in table \ref{tab:clreport:before}, while the results after using the described method are shown in table \ref{tab:distrep}.

\begin{table}[H]
    \centering
    \caption{Classification report after using the distance routine} \label{tab:distrep}
    \begin{tabular}{rcccc}\toprule
     &   precision    &recall & f1-score &  support  \\\midrule

        NoEvents    &   0.72   &   0.79   &   0.75  &   51797 \\
          Attack    &   0.28   &   0.23   &   0.25  &   17382 \\
         Natural   &    0.19   &   0.08   &   0.11  &    4232 \\
    
        accuracy    &           &         &   0.62   &  73411 \\
       macro avg    &   0.40    &  0.37   &   0.37  &   73411 \\
    weighted avg   &   0.58   &   0.62   &   0.60   &  73411   \\  \bottomrule
    \end{tabular}
\end{table}

Tables \ref{tab:clreport:before} and \ref{tab:distrep} show an increase of model's accuracy by $0.02$. Precision value for Attack class increased by 0.01, with no changes for other classes. Recall value increased for NoEvents by 0.03 and decreased for Attack by 0.03. Finally, f-measure increased for NoEvents class and decreased by 0.01 for other classes. The f-measure value difference for Natural class, despite the same precision and recall, is due to rounding numbers to two decimal places. 

It may be concluded that this method does not really enhance the results, despite the better accuracy. For the other metrics, ones increased, but other decreased, what makes the obtained result less satisfying. In addition to that, the same problem with unequal class distribution mentioned in previous method discussion arises. 
\section{Hidden Markov Models}
