{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base algorithm for features' importance classification for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "labels = [\"NoEvents\", \"Attack\", \"Natural\"]\n",
    "\n",
    "X = pd.read_csv(\"Data/data%d.csv\"%1) #read file\n",
    "\n",
    "X = X.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#preparing the label converter\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "y = le.transform(X['marker'])\n",
    "X = X.drop(columns='marker')\n",
    "\n",
    "features = list(X.columns)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000, early_stopping=True)\n",
    "X=X.values\n",
    "\n",
    "clf.fit(X,y)\n",
    "\n",
    "explainer = LimeTabularExplainer(X, training_labels = y, feature_names = features, class_names = labels)\n",
    "\n",
    "\n",
    "Xall = []\n",
    "for i in range(2,16):\n",
    "    Xall.append(pd.read_csv(\"Data/data%d.csv\"%i))\n",
    "\n",
    "Xall = pd.concat(Xall)\n",
    "Xall = Xall.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "yall = le.transform(Xall['marker'])\n",
    "Xall = Xall.drop(columns='marker')\n",
    "\n",
    "boole = (yall != clf.predict(Xall))\n",
    "\n",
    "res = []\n",
    "\n",
    "for act_class in [0, 1, 2]:\n",
    "    faulty = boole & (yall == act_class)\n",
    "    X_test = Xall[faulty]\n",
    "    y_test = yall[faulty]\n",
    "    lst = []\n",
    "    for idx in range(0, 100):\n",
    "        exp = explainer.explain_instance(X_test.iloc[idx], clf.predict_proba, num_features=128, labels=[0, 1, 2])\n",
    "        lst.append(exp.as_list(label=0))\n",
    "    lst = np.array(lst)\n",
    "    clst = np.concatenate(lst, axis=0)\n",
    "    dtfr = pd.DataFrame(clst, columns=['feature', 'importance'])\n",
    "    dtfr[\"importance\"] = pd.to_numeric(dtfr[\"importance\"])\n",
    "    dtfr = dtfr.groupby(['feature']).mean()\n",
    "    res.append(dtfr.sort_values(by=\"importance\"))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[                       importance\n feature                          \n R1-PA9:VH > 0.00        -0.155915\n R3-PM1:V <= 128600.80   -0.151731\n R2-PA:Z > 12.11         -0.120849\n R3-PM9:V <= 0.00        -0.075508\n R4-PM8:V <= 0.00        -0.071103\n ...                           ...\n R1-PM7:V > 132060.91     0.042774\n R1:S > 0.00              0.053059\n R3-PM9:V > 0.00          0.066984\n R3-PM3:V <= 128676.02    0.082892\n R4-PM8:V > 0.00          0.111197\n \n [316 rows x 1 columns],                                    importance\n feature                                      \n R3-PM1:V <= 128600.80               -0.149137\n R2-PA:Z > 12.11                     -0.118818\n R3-PM9:V <= 0.00                    -0.075927\n R4-PM8:V <= 0.00                    -0.070603\n R2-PM1:V <= 128762.21               -0.066452\n ...                                       ...\n R3-PM7:V <= 128600.80                0.041327\n 128600.80 < R3-PM1:V <= 129704.03    0.041568\n 129704.03 < R3-PM1:V <= 130631.74    0.052262\n R3-PM1:V > 130631.74                 0.061883\n R3-PM3:V <= 128676.02                0.084712\n \n [363 rows x 1 columns],                                    importance\n feature                                      \n R3-PM1:V <= 128600.80               -0.154577\n R2-PA:Z > 12.11                     -0.113696\n R4-PM8:V <= 0.00                    -0.073176\n R2-PM1:V <= 128762.21               -0.066305\n R3-PM9:V <= 0.00                    -0.065383\n ...                                       ...\n 128600.80 < R3-PM1:V <= 129704.03    0.039490\n 9.59 < R2-PA:Z <= 12.11              0.039845\n 129704.03 < R3-PM1:V <= 130631.74    0.047072\n R3-PM1:V > 130631.74                 0.058216\n R3-PM3:V <= 128676.02                0.081114\n \n [331 rows x 1 columns]]"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosen features values modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.71      0.99      0.83     51797\n      Attack       0.57      0.05      0.09     17382\n     Natural       0.00      0.00      0.00      4232\n\n    accuracy                           0.71     73411\n   macro avg       0.43      0.35      0.30     73411\nweighted avg       0.64      0.71      0.60     73411\n\n"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yall, clf.predict(Xall), labels=[0,1,2], target_names=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xmod = Xall.copy()\n",
    "\n",
    "def modify(feat, val):\n",
    "    Xmod[feat] =Xmod[feat].apply(lambda x: x + val)\n",
    "\n",
    "\n",
    "modify(\"R4-PM8:V\", 0)\n",
    "modify(\"R3-PM3:V\", 128676.02)\n",
    "modify(\"R3-PM9:V\", 0)\n",
    "modify(\"R1:S\", 0)\n",
    "modify(\"R1-PM7:V\", -132060.91)\n",
    "\n",
    "modify(\"R3-PM3:V\", 128676.02)\n",
    "modify(\"R3-PM1:V\", -130631.74)\n",
    "modify(\"R3-PM7:V\", 128600.80)\n",
    "\n",
    "modify(\"R3-PM3:V\", 128676.02)\n",
    "modify(\"R2-PA:Z\", 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.74      0.07      0.12     51797\n      Attack       0.24      0.93      0.38     17382\n     Natural       0.00      0.00      0.00      4232\n\n    accuracy                           0.27     73411\n   macro avg       0.33      0.33      0.17     73411\nweighted avg       0.58      0.27      0.17     73411\n\n"
    }
   ],
   "source": [
    "print(classification_report(yall, clf.predict(Xmod), labels=[0,1,2], target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance:\n",
    "    def __init__(self):\n",
    "        self.noevents = None\n",
    "        self.attack = None\n",
    "        self.natural = None\n",
    "\n",
    "    def distance(self, X1, X2):\n",
    "        return np.abs(((X1 - X2).sum()))\n",
    "\n",
    "    def important(self, X):\n",
    "        return X[[\"R4-PM8:V\",\"R3-PM3:V\",\"R3-PM9:V\",\"R1:S\",\"R1-PM7:V\", \"R3-PM3:V\",\"R3-PM1:V\", \"R3-PM7:V\",\"R3-PM3:V\",\"R2-PA:Z\"]]\n",
    "   \n",
    "    def fit(self, X, y):\n",
    "        Xnew = self.important(X)\n",
    "        self.noevents = Xnew[y == 0].mean(axis=0)\n",
    "        self.attack = Xnew[y == 1].mean(axis=0)\n",
    "        self.natural = Xnew[y == 2].mean(axis=0)     \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        Xnew = self.important(X)\n",
    "        res = np.c_[np.apply_along_axis(lambda x: self.distance(x, self.noevents), axis=1, arr=Xnew), np.apply_along_axis(lambda x: self.distance(x, self.attack), axis=1, arr=Xnew), np.apply_along_axis(lambda x: self.distance(x, self.natural), axis=1, arr=Xnew)]\n",
    "        return np.c_[Xnew, np.argmin(res, axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(steps=[('dist', <__main__.Distance object at 0x0000023C52FBC9C8>),\n                ('MLP',\n                 MLPClassifier(early_stopping=True, hidden_layer_sizes=(20,),\n                               max_iter=1000))])"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "labels = [\"NoEvents\", \"Attack\", \"Natural\"]\n",
    "\n",
    "X = pd.read_csv(\"Data/data%d.csv\"%1) #read file\n",
    "\n",
    "X = X.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#preparing the label converter\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels)\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "y = le.transform(X['marker'])\n",
    "X = X.drop(columns='marker')\n",
    "\n",
    "pipe = Pipeline([('dist', Distance()) , ('MLP', MLPClassifier(hidden_layer_sizes=(20,), max_iter=1000, early_stopping=True))])\n",
    "pipe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "precision    recall  f1-score   support\n\n    NoEvents       0.70      0.98      0.82     51797\n      Attack       0.18      0.01      0.02     17382\n     Natural       0.00      0.00      0.00      4232\n\n    accuracy                           0.69     73411\n   macro avg       0.29      0.33      0.28     73411\nweighted avg       0.54      0.69      0.58     73411\n\n"
    }
   ],
   "source": [
    "Xall = []\n",
    "for i in range(2,16):\n",
    "    Xall.append(pd.read_csv(\"Data/data%d.csv\"%i))\n",
    "\n",
    "Xall = pd.concat(Xall)\n",
    "Xall = Xall.replace(np.inf, np.finfo(np.float32).max) #replacing 'inf' with its equivalent in float32 datatype\n",
    "\n",
    "#assigning the training data and the labels into variables\n",
    "yall = le.transform(Xall['marker'])\n",
    "Xall = Xall.drop(columns='marker')\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(yall, pipe.predict(Xall), labels=[0,1,2], target_names=labels))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598715048419",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}